{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retail Promotional Event Analysis\n",
    "## Measuring Marketing Effectiveness Through Statistical Testing\n",
    "\n",
    "**Author:** Jacob Aguillard  \n",
    "**Portfolio Project**\n",
    "\n",
    "---\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "This analysis examines the effectiveness of various promotional tactics (endcap placement, coupons, digital signage, QR codes) on Return on Investment (ROI) across different retail departments.\n",
    "\n",
    "**Business Questions:**\n",
    "1. Which promotional tactics significantly improve ROI?\n",
    "2. Do certain tactics work better in specific departments?\n",
    "3. How can we quantify the incremental value of each tactic?\n",
    "\n",
    "**Methods Used:**\n",
    "- Independent t-tests with Cohen's d effect sizes\n",
    "- Chi-square tests for categorical comparisons  \n",
    "- Z-tests for proportion comparisons\n",
    "- Data winsorization for outlier handling\n",
    "\n",
    "**Tools:** Python, Pandas, SciPy, NumPy, Matplotlib\n",
    "\n",
    "---\n",
    "\n",
    "*Note: This analysis uses synthetic data that preserves the statistical properties of real promotional event data while protecting proprietary information.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats.mstats import winsorize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the synthetic retail promotions data\n",
    "df = pd.read_csv('synthetic_retail_promotions.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape[0]:,} records x {df.shape[1]} columns\")\n",
    "print(f\"\\nDate range: {df['event_date'].min()} to {df['event_date'].max()}\")\n",
    "print(f\"Departments: {df['department'].nunique()}\")\n",
    "print(f\"Regions: {df['region'].nunique()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info and summary statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA TYPES\")\n",
    "print(\"=\" * 60)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data analysis\n",
    "missing_analysis = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100,\n",
    "    'Data_Type': df.dtypes\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(\"MISSING DATA ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "missing_with_nulls = missing_analysis[missing_analysis['Missing_Percentage'] > 0]\n",
    "if len(missing_with_nulls) > 0:\n",
    "    print(missing_with_nulls)\n",
    "else:\n",
    "    print(\"No missing values detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection using IQR method\n",
    "print(\"OUTLIER DETECTION (IQR Method)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "outlier_summary = []\n",
    "\n",
    "for col in ['roi_per_dollar', 'roi_winsorized', 'total_event_sales', 'sales_lift']:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
    "    outlier_pct = len(outliers) / len(df) * 100\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Range: {df[col].min():.2f} to {df[col].max():.2f}\")\n",
    "    print(f\"  IQR bounds: {lower_bound:.2f} to {upper_bound:.2f}\")\n",
    "    print(f\"  Outliers: {len(outliers):,} ({outlier_pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reusable Statistical Analysis Functions\n",
    "\n",
    "These functions form the core analytical framework for testing promotional effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_by_group(df: pd.DataFrame, target: str, measure: str, group_col: str):\n",
    "    \"\"\"\n",
    "    Perform independent t-tests comparing a measure between groups with and without \n",
    "    a target feature, analyzed separately for each category in group_col.\n",
    "    \n",
    "    This function conducts statistical analysis to determine whether a binary feature \n",
    "    (e.g., end_cap, has_coupon) significantly impacts a measure (e.g., ROI) across \n",
    "    different departments or categories.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame containing the data to analyze.\n",
    "    target : str\n",
    "        Name of the binary column to test (0/1 values).\n",
    "    measure : str\n",
    "        Name of the numeric column to compare between groups.\n",
    "    group_col : str\n",
    "        Name of the column containing group identifiers (e.g., 'department').\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Results DataFrame with t-test statistics for each group.\n",
    "    \n",
    "    Output Includes\n",
    "    ---------------\n",
    "    - Sample sizes for each group\n",
    "    - Mean values for groups with/without the target feature\n",
    "    - Mean difference (effect size)\n",
    "    - Incremental dollar impact\n",
    "    - T-statistic and p-value\n",
    "    - Cohen's d effect size\n",
    "    - Significance indicators (*, **, ***)\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - Significance levels: * p<0.05, ** p<0.01, *** p<0.001\n",
    "    - Positive Mean_Difference indicates target feature improves the measure\n",
    "    - Cohen's d interpretation: 0.2 = small, 0.5 = medium, 0.8 = large\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate inputs\n",
    "    if group_col not in df.columns or target not in df.columns:\n",
    "        raise ValueError(f\"Column not found in DataFrame\")\n",
    "    \n",
    "    # Clean data - remove missing values\n",
    "    test_data = df[[target, measure, group_col]].dropna()\n",
    "    \n",
    "    # Initialize results storage\n",
    "    t_test_results = []\n",
    "    \n",
    "    # Get unique groups\n",
    "    groups = test_data[group_col].unique()\n",
    "    \n",
    "    # Ensure target is binary (0/1)\n",
    "    if test_data[target].dtype == object:\n",
    "        test_data[target] = np.where(test_data[target] == \"Yes\", 1, 0)\n",
    "    elif test_data[target].dtype in [float, int]:\n",
    "        test_data[target] = np.where(test_data[target] > 0, 1, 0)\n",
    "    \n",
    "    # Perform t-test for each group\n",
    "    for group in groups:\n",
    "        group_data = test_data[test_data[group_col] == group]\n",
    "        \n",
    "        # Separate by target\n",
    "        no_target = group_data[group_data[target] == 0][measure]\n",
    "        has_target = group_data[group_data[target] == 1][measure]\n",
    "        \n",
    "        # Check if both groups have sufficient data\n",
    "        if len(no_target) >= 2 and len(has_target) >= 2:\n",
    "            # Perform independent t-test\n",
    "            t_statistic, p_value = stats.ttest_ind(has_target, no_target)\n",
    "            \n",
    "            # Calculate Cohen's d effect size\n",
    "            pooled_std = np.sqrt(\n",
    "                ((len(has_target) - 1) * has_target.var() + \n",
    "                 (len(no_target) - 1) * no_target.var()) /\n",
    "                (len(has_target) + len(no_target) - 2)\n",
    "            )\n",
    "            cohens_d = (has_target.mean() - no_target.mean()) / pooled_std if pooled_std > 0 else 0\n",
    "            \n",
    "            # Calculate means and differences\n",
    "            mean_no_target = no_target.mean()\n",
    "            mean_has_target = has_target.mean()\n",
    "            mean_diff = mean_has_target - mean_no_target\n",
    "            \n",
    "            # Calculate incremental dollars\n",
    "            incremental_dollars = mean_diff * len(has_target)\n",
    "            \n",
    "            # Determine significance level\n",
    "            if p_value < 0.001:\n",
    "                significance = \"***\"\n",
    "            elif p_value < 0.01:\n",
    "                significance = \"**\"\n",
    "            elif p_value < 0.05:\n",
    "                significance = \"*\"\n",
    "            else:\n",
    "                significance = \"\"\n",
    "            \n",
    "            t_test_results.append({\n",
    "                'Group': group,\n",
    "                f'N_Without_{target}': len(no_target),\n",
    "                f'N_With_{target}': len(has_target),\n",
    "                f'Mean_Without': round(mean_no_target, 4),\n",
    "                f'Mean_With': round(mean_has_target, 4),\n",
    "                'Mean_Difference': round(mean_diff, 4),\n",
    "                'Incremental_$': round(incremental_dollars, 2),\n",
    "                'T_Statistic': round(t_statistic, 4),\n",
    "                'P_Value': round(p_value, 6),\n",
    "                'Cohens_D': round(cohens_d, 4),\n",
    "                'Significance': significance\n",
    "            })\n",
    "        else:\n",
    "            t_test_results.append({\n",
    "                'Group': group,\n",
    "                f'N_Without_{target}': len(no_target),\n",
    "                f'N_With_{target}': len(has_target),\n",
    "                f'Mean_Without': no_target.mean() if len(no_target) > 0 else np.nan,\n",
    "                f'Mean_With': has_target.mean() if len(has_target) > 0 else np.nan,\n",
    "                'Mean_Difference': np.nan,\n",
    "                'Incremental_$': np.nan,\n",
    "                'T_Statistic': np.nan,\n",
    "                'P_Value': np.nan,\n",
    "                'Cohens_D': np.nan,\n",
    "                'Significance': 'Insufficient Data'\n",
    "            })\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(t_test_results).sort_values('P_Value')\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"T-TEST ANALYSIS: {target.upper()} EFFECT ON {measure.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nRecords analyzed: {len(test_data):,}\")\n",
    "    print(f\"Groups analyzed: {len(groups)}\")\n",
    "    print(f\"\\nSignificance levels: *** p<0.001, ** p<0.01, * p<0.05\")\n",
    "    print(f\"Positive Mean_Difference = {target} improves {measure}\")\n",
    "    print(f\"\\n{'-'*80}\")\n",
    "    \n",
    "    # Count significant results\n",
    "    significant = results_df[results_df['P_Value'] < 0.05]\n",
    "    helps = significant[significant['Mean_Difference'] > 0]\n",
    "    hurts = significant[significant['Mean_Difference'] < 0]\n",
    "    \n",
    "    print(f\"\\nSUMMARY:\")\n",
    "    print(f\"  Statistically significant results (p<0.05): {len(significant)}\")\n",
    "    print(f\"  Groups where {target} HELPS: {len(helps)}\")\n",
    "    print(f\"  Groups where {target} HURTS: {len(hurts)}\")\n",
    "    \n",
    "    if len(helps) > 0:\n",
    "        print(f\"\\nGROUPS WHERE {target.upper()} SIGNIFICANTLY HELPS:\")\n",
    "        for _, row in helps.iterrows():\n",
    "            print(f\"  {row['Group']}: +{row['Mean_Difference']:.3f} (p={row['P_Value']:.4f}) {row['Significance']}\")\n",
    "    \n",
    "    if len(hurts) > 0:\n",
    "        print(f\"\\nGROUPS WHERE {target.upper()} SIGNIFICANTLY HURTS:\")\n",
    "        for _, row in hurts.iterrows():\n",
    "            print(f\"  {row['Group']}: {row['Mean_Difference']:.3f} (p={row['P_Value']:.4f}) {row['Significance']}\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ROI Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI Distribution by Department\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Original ROI distribution\n",
    "axes[0].hist(df['roi_per_dollar'].clip(-5, 15), bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(df['roi_per_dollar'].median(), color='red', linestyle='--', label=f'Median: {df[\"roi_per_dollar\"].median():.2f}')\n",
    "axes[0].axvline(df['roi_per_dollar'].mean(), color='green', linestyle='--', label=f'Mean: {df[\"roi_per_dollar\"].mean():.2f}')\n",
    "axes[0].set_title('ROI per Dollar Spent Distribution')\n",
    "axes[0].set_xlabel('ROI')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].legend()\n",
    "\n",
    "# Winsorized ROI distribution  \n",
    "axes[1].hist(df['roi_winsorized'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].axvline(df['roi_winsorized'].median(), color='red', linestyle='--', label=f'Median: {df[\"roi_winsorized\"].median():.2f}')\n",
    "axes[1].axvline(df['roi_winsorized'].mean(), color='green', linestyle='--', label=f'Mean: {df[\"roi_winsorized\"].mean():.2f}')\n",
    "axes[1].set_title('Winsorized ROI Distribution (5th-95th percentile)')\n",
    "axes[1].set_xlabel('ROI')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Original ROI - Mean: {df['roi_per_dollar'].mean():.3f}, Median: {df['roi_per_dollar'].median():.3f}, Std: {df['roi_per_dollar'].std():.3f}\")\n",
    "print(f\"Winsorized ROI - Mean: {df['roi_winsorized'].mean():.3f}, Median: {df['roi_winsorized'].median():.3f}, Std: {df['roi_winsorized'].std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI by Department\n",
    "dept_roi = df.groupby('department')['roi_winsorized'].agg(['mean', 'median', 'std', 'count']).round(3)\n",
    "dept_roi = dept_roi.sort_values('mean', ascending=False)\n",
    "\n",
    "print(\"ROI BY DEPARTMENT\")\n",
    "print(\"=\" * 60)\n",
    "print(dept_roi)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['green' if x > df['roi_winsorized'].mean() else 'coral' for x in dept_roi['mean']]\n",
    "plt.barh(dept_roi.index, dept_roi['mean'], color=colors, edgecolor='black')\n",
    "plt.axvline(df['roi_winsorized'].mean(), color='red', linestyle='--', linewidth=2, label=f'Overall Mean: {df[\"roi_winsorized\"].mean():.2f}')\n",
    "plt.xlabel('Mean ROI (Winsorized)')\n",
    "plt.title('Average ROI by Department')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Promotional Tactic Analysis\n",
    "\n",
    "### 5.1 End Cap Placement Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze end cap effect on ROI by department\n",
    "endcap_results = t_test_by_group(\n",
    "    df=df, \n",
    "    target='end_cap', \n",
    "    measure='roi_winsorized', \n",
    "    group_col='department'\n",
    ")\n",
    "\n",
    "# Display full results table\n",
    "print(\"\\nFULL RESULTS TABLE:\")\n",
    "endcap_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize end cap effect\n",
    "significant_endcap = endcap_results[endcap_results['P_Value'] < 0.05].copy()\n",
    "\n",
    "if len(significant_endcap) > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    colors = ['green' if x > 0 else 'red' for x in significant_endcap['Mean_Difference']]\n",
    "    plt.barh(significant_endcap['Group'], significant_endcap['Mean_Difference'], color=colors, edgecolor='black')\n",
    "    plt.axvline(0, color='black', linewidth=1)\n",
    "    plt.xlabel('ROI Difference (With End Cap - Without)')\n",
    "    plt.title('Significant End Cap Effects by Department (p < 0.05)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No statistically significant end cap effects found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Coupon Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze coupon effect on ROI by department\n",
    "coupon_results = t_test_by_group(\n",
    "    df=df, \n",
    "    target='has_coupon', \n",
    "    measure='roi_winsorized', \n",
    "    group_col='department'\n",
    ")\n",
    "\n",
    "coupon_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coupon effect\n",
    "significant_coupon = coupon_results[coupon_results['P_Value'] < 0.05].copy()\n",
    "\n",
    "if len(significant_coupon) > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    colors = ['green' if x > 0 else 'red' for x in significant_coupon['Mean_Difference']]\n",
    "    plt.barh(significant_coupon['Group'], significant_coupon['Mean_Difference'], color=colors, edgecolor='black')\n",
    "    plt.axvline(0, color='black', linewidth=1)\n",
    "    plt.xlabel('ROI Difference (With Coupon - Without)')\n",
    "    plt.title('Significant Coupon Effects by Department (p < 0.05)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Digital Signage Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze digital signage effect\n",
    "digital_results = t_test_by_group(\n",
    "    df=df, \n",
    "    target='digital_signage', \n",
    "    measure='roi_winsorized', \n",
    "    group_col='department'\n",
    ")\n",
    "\n",
    "digital_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 QR Code Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze QR code effect\n",
    "qr_results = t_test_by_group(\n",
    "    df=df, \n",
    "    target='qr_code', \n",
    "    measure='roi_winsorized', \n",
    "    group_col='department'\n",
    ")\n",
    "\n",
    "qr_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conversion Rate Analysis by Day of Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add day of week\n",
    "df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "df['day_of_week'] = df['event_date'].dt.day_name()\n",
    "\n",
    "# Conversion rate by day of week\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "day_stats = df.groupby('day_of_week').agg({\n",
    "    'conversion_rate': ['mean', 'std', 'count'],\n",
    "    'roi_winsorized': ['mean', 'std']\n",
    "}).round(4)\n",
    "\n",
    "day_stats = day_stats.reindex(day_order)\n",
    "print(\"PERFORMANCE BY DAY OF WEEK\")\n",
    "print(\"=\" * 60)\n",
    "print(day_stats)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "conv_by_day = df.groupby('day_of_week')['conversion_rate'].mean().reindex(day_order)\n",
    "axes[0].bar(conv_by_day.index, conv_by_day.values, color='steelblue', edgecolor='black')\n",
    "axes[0].axhline(df['conversion_rate'].mean(), color='red', linestyle='--', label='Overall Mean')\n",
    "axes[0].set_title('Average Conversion Rate by Day of Week')\n",
    "axes[0].set_ylabel('Conversion Rate')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].legend()\n",
    "\n",
    "roi_by_day = df.groupby('day_of_week')['roi_winsorized'].mean().reindex(day_order)\n",
    "axes[1].bar(roi_by_day.index, roi_by_day.values, color='coral', edgecolor='black')\n",
    "axes[1].axhline(df['roi_winsorized'].mean(), color='red', linestyle='--', label='Overall Mean')\n",
    "axes[1].set_title('Average ROI by Day of Week')\n",
    "axes[1].set_ylabel('ROI (Winsorized)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Chi-Square Test: Day of Week Effect by Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_day_effect_by_department(df, department_col='department'):\n",
    "    \"\"\"\n",
    "    Perform chi-square tests to determine if day of week significantly\n",
    "    affects conversion rates within each department.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for dept in df[department_col].unique():\n",
    "        dept_data = df[df[department_col] == dept]\n",
    "        \n",
    "        # Create contingency table: day of week vs high/low conversion\n",
    "        dept_data = dept_data.copy()\n",
    "        median_conv = dept_data['conversion_rate'].median()\n",
    "        dept_data['high_conversion'] = (dept_data['conversion_rate'] > median_conv).astype(int)\n",
    "        \n",
    "        contingency = pd.crosstab(dept_data['day_of_week'], dept_data['high_conversion'])\n",
    "        \n",
    "        if contingency.shape[0] >= 2 and contingency.shape[1] >= 2:\n",
    "            chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "            \n",
    "            results.append({\n",
    "                'Department': dept,\n",
    "                'Chi2_Statistic': round(chi2, 4),\n",
    "                'P_Value': round(p_value, 6),\n",
    "                'Degrees_Freedom': dof,\n",
    "                'Days_Matter': 'Yes' if p_value < 0.05 else 'No'\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results).sort_values('P_Value')\n",
    "    \n",
    "    print(\"CHI-SQUARE TEST: Does Day of Week Affect Conversion by Department?\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nDepartments where day significantly matters (p<0.05): {len(results_df[results_df['Days_Matter']=='Yes'])}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "day_effect_results = analyze_day_effect_by_department(df)\n",
    "day_effect_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary of Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"EXECUTIVE SUMMARY: PROMOTIONAL EFFECTIVENESS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "DATASET OVERVIEW:\n",
    "- Total promotional events analyzed: {len(df):,}\n",
    "- Departments: {df['department'].nunique()}\n",
    "- Regions: {df['region'].nunique()}\n",
    "- Date range: {df['event_date'].min().date()} to {df['event_date'].max().date()}\n",
    "\n",
    "KEY METRICS:\n",
    "- Average ROI per dollar spent: {df['roi_winsorized'].mean():.2f}\n",
    "- Median ROI: {df['roi_winsorized'].median():.2f}\n",
    "- Average conversion rate: {df['conversion_rate'].mean():.2%}\n",
    "- Average sales lift: ${df['sales_lift'].mean():,.2f}\n",
    "\n",
    "PROMOTIONAL TACTIC FINDINGS:\n",
    "\"\"\")\n",
    "\n",
    "# Summarize each tactic\n",
    "tactics = [\n",
    "    ('End Cap Placement', endcap_results),\n",
    "    ('Coupons', coupon_results),\n",
    "    ('Digital Signage', digital_results),\n",
    "    ('QR Codes', qr_results)\n",
    "]\n",
    "\n",
    "for tactic_name, results in tactics:\n",
    "    sig_helps = results[(results['P_Value'] < 0.05) & (results['Mean_Difference'] > 0)]\n",
    "    sig_hurts = results[(results['P_Value'] < 0.05) & (results['Mean_Difference'] < 0)]\n",
    "    \n",
    "    print(f\"{tactic_name}:\")\n",
    "    print(f\"  - Departments with significant positive effect: {len(sig_helps)}\")\n",
    "    print(f\"  - Departments with significant negative effect: {len(sig_hurts)}\")\n",
    "    if len(sig_helps) > 0:\n",
    "        top_dept = sig_helps.iloc[0]\n",
    "        print(f\"  - Strongest positive effect: {top_dept['Group']} (+{top_dept['Mean_Difference']:.3f} ROI)\")\n",
    "    print()\n",
    "\n",
    "print(\"\"\"\n",
    "RECOMMENDATIONS:\n",
    "1. Prioritize end cap placement for Food division departments where effect is strongest\n",
    "2. Deploy coupons strategically in Snacks, Frozen, Beverages, and Dairy departments\n",
    "3. Consider department-specific promotional strategies rather than one-size-fits-all\n",
    "4. Further investigate departments where tactics show negative effects\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## About This Analysis\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Statistical Testing** - Independent t-tests, chi-square tests, effect size calculations (Cohen's d)\n",
    "2. **Data Quality Assessment** - Missing data analysis, outlier detection, winsorization\n",
    "3. **Reusable Code** - Parameterized functions for repeatable analysis\n",
    "4. **Business Insight Generation** - Translating statistical results into actionable recommendations\n",
    "5. **Data Visualization** - Clear charts that communicate findings effectively\n",
    "\n",
    "**Technical Stack:** Python, Pandas, NumPy, SciPy, Matplotlib, Seaborn\n",
    "\n",
    "**Author:** Jacob Aguillard  \n",
    "**Contact:** aguillarj@gmail.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
